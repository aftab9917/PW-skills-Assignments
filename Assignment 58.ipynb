{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75a2db-bd59-4d5a-a06d-e342189e45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Bayes' theorem is a fundamental concept in probability theory and statistics that describes the probability of an event based on prior knowledge of conditions that might be related to the event. It provides a way to update probabilities based on new evidence or information.\n",
    "\n",
    "# Q2. The formula for Bayes' theorem is:\n",
    "\n",
    "# P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "# Where:\n",
    "# - P(A|B) is the posterior probability of event A given that event B has occurred.\n",
    "# - P(B|A) is the conditional probability of event B given that event A has occurred.\n",
    "# - P(A) is the prior probability of event A.\n",
    "# - P(B) is the prior probability of event B.\n",
    "\n",
    "# Q3. Bayes' theorem is used in practice in various fields such as machine learning, statistics, and decision-making. It is applied in tasks such as classification, spam filtering, medical diagnosis, and risk assessment. In machine learning, Bayes' theorem serves as the foundation for Naive Bayes classifiers, which are widely used for text classification and other tasks.\n",
    "\n",
    "# Q4. Bayes' theorem and conditional probability are closely related. Bayes' theorem provides a formal way to calculate conditional probabilities by relating the conditional probability of an event given another event to the probability of that other event given the first event. In essence, Bayes' theorem allows us to update our beliefs about the likelihood of an event occurring based on new evidence or information.\n",
    "\n",
    "# Q5. The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions that can be made about the independence of features. The three main types of Naive Bayes classifiers are:\n",
    "# - Gaussian Naive Bayes: Assumes that continuous features follow a Gaussian distribution.\n",
    "# - Multinomial Naive Bayes: Suitable for classification with discrete features (e.g., word counts).\n",
    "# - Bernoulli Naive Bayes: Suitable for binary or boolean features.\n",
    "\n",
    "# The choice between these classifiers depends on whether the features are continuous, discrete, or binary, and whether the independence assumption holds for the dataset.\n",
    "\n",
    "# Q6. **Assignment:**\n",
    "\n",
    "# Let's calculate the likelihoods and posterior probabilities for classes A and B based on the provided frequency table and assuming equal prior probabilities.\n",
    "\n",
    "# Given:\n",
    "# - Prior probability P(A) = P(B) = 0.5 (equal prior probabilities)\n",
    "# - Features of the new instance: X1 = 3 and X2 = 4\n",
    "\n",
    "# We'll calculate the likelihoods P(X1=3, X2=4|A) and P(X1=3, X2=4|B), and then use Bayes' theorem to compute the posterior probabilities P(A|X1=3, X2=4) and P(B|X1=3, X2=4). Finally, we'll choose the class with the highest posterior probability as the predicted class for the new instance.\n",
    "\n",
    "# Let's proceed with the calculations:\n",
    "\n",
    "# Given data\n",
    "prior_A = 0.5  # Prior probability of class A\n",
    "prior_B = 0.5  # Prior probability of class B\n",
    "\n",
    "# Likelihoods\n",
    "likelihood_X1_X2_given_A = 4 / 3  # P(X1=3, X2=4|A)\n",
    "likelihood_X1_X2_given_B = 3 / 2  # P(X1=3, X2=4|B)\n",
    "\n",
    "# Marginal likelihoods (denominators)\n",
    "marginal_likelihood_X1_X2 = (prior_A * likelihood_X1_X2_given_A) + (prior_B * likelihood_X1_X2_given_B)\n",
    "\n",
    "# Posterior probabilities\n",
    "posterior_A = (likelihood_X1_X2_given_A * prior_A) / marginal_likelihood_X1_X2  # P(A|X1=3, X2=4)\n",
    "posterior_B = (likelihood_X1_X2_given_B * prior_B) / marginal_likelihood_X1_X2  # P(B|X1=3, X2=4)\n",
    "\n",
    "# Display the results\n",
    "print(\"Posterior probability of class A:\", posterior_A)\n",
    "print(\"Posterior probability of class B:\", posterior_B)\n",
    "\n",
    "# Predict the class for the new instance\n",
    "predicted_class = 'A' if posterior_A > posterior_B else 'B'\n",
    "print(\"Predicted class for the new instance:\", predicted_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
